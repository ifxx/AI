{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sap-llm-commons[all] in c:\\python\\3.11\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (8.1.7)\n",
      "Requirement already satisfied: text-generation>=0.6.0 in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (0.6.1)\n",
      "Requirement already satisfied: omegaconf in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (2.3.0)\n",
      "Requirement already satisfied: aleph-alpha-client in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (7.0.0)\n",
      "Requirement already satisfied: ai-core-sdk in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (1.22.3)\n",
      "Requirement already satisfied: langchain<=0.0.335,>=0.0.331 in c:\\python\\3.11\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.0.335)\n",
      "Requirement already satisfied: cohere>=4.27 in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (4.45)\n",
      "Requirement already satisfied: openai<1 in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (0.28.1)\n",
      "Requirement already satisfied: colorama in c:\\python\\3.11\\lib\\site-packages (from click>=8.1.3->sap-llm-commons[all]) (0.4.6)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (3.9.1)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2.0,>=1.8 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (1.9.3)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (6.11.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (2.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2.0.25)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.0.84)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2.5.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (8.2.3)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.3.2 in c:\\python\\3.11\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.5.2)\n",
      "Requirement already satisfied: tqdm in c:\\python\\3.11\\lib\\site-packages (from openai<1->sap-llm-commons[all]) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.12 in c:\\python\\3.11\\lib\\site-packages (from text-generation>=0.6.0->sap-llm-commons[all]) (0.20.3)\n",
      "Requirement already satisfied: ai-api-client-sdk==1.28.0 in c:\\python\\3.11\\lib\\site-packages (from ai-core-sdk->sap-llm-commons[all]) (1.28.0)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk==1.28.0->ai-core-sdk->sap-llm-commons[all]) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk==1.28.0->ai-core-sdk->sap-llm-commons[all]) (3.8.0)\n",
      "Requirement already satisfied: aiodns>=3.0.0 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (3.1.1)\n",
      "Requirement already satisfied: aiohttp-retry>=2.8.3 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (2.8.3)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (4.6.2)\n",
      "Requirement already satisfied: Pillow>=9.2.0 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (9.5.0)\n",
      "Requirement already satisfied: python-liquid>=1.9.4 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (1.10.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (23.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\python\\3.11\\lib\\site-packages (from omegaconf->sap-llm-commons[all]) (4.9.3)\n",
      "Requirement already satisfied: pycares>=4.0.0 in c:\\python\\3.11\\lib\\site-packages (from aiodns>=3.0.0->aleph-alpha-client->sap-llm-commons[all]) (4.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python\\3.11\\lib\\site-packages (from anyio<4.0->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python\\3.11\\lib\\site-packages (from anyio<4.0->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python\\3.11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python\\3.11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\python\\3.11\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text-generation>=0.6.0->sap-llm-commons[all]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python\\3.11\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text-generation>=0.6.0->sap-llm-commons[all]) (2023.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python\\3.11\\lib\\site-packages (from importlib_metadata<7.0,>=6.0->cohere>=4.27->sap-llm-commons[all]) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python\\3.11\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python\\3.11\\lib\\site-packages (from pydantic<3,>=1->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\python\\3.11\\lib\\site-packages (from pydantic<3,>=1->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2.14.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python\\3.11\\lib\\site-packages (from python-liquid>=1.9.4->aleph-alpha-client->sap-llm-commons[all]) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0.0,>=2.25.0->cohere>=4.27->sap-llm-commons[all]) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0.0,>=2.25.0->cohere>=4.27->sap-llm-commons[all]) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python\\3.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python\\3.11\\lib\\site-packages (from tiktoken<0.6.0,>=0.3.2->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2023.12.25)\n",
      "Requirement already satisfied: cffi>=1.5.0 in c:\\python\\3.11\\lib\\site-packages (from pycares>=4.0.0->aiodns>=3.0.0->aleph-alpha-client->sap-llm-commons[all]) (1.15.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\3.11\\lib\\site-packages (from python-dateutil>=2.8.1->python-liquid>=1.9.4->aleph-alpha-client->sap-llm-commons[all]) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python\\3.11\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (1.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\python\\3.11\\lib\\site-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns>=3.0.0->aleph-alpha-client->sap-llm-commons[all]) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sap-llm-commons[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ai-api-client-sdk in c:\\python\\3.11\\lib\\site-packages (1.28.0)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk) (3.8.0)\n",
      "Requirement already satisfied: requests<3.0 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ai-api-client-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylin\\AppData\\Local\\Temp\\ipykernel_2352\\3646097473.py:5: UserWarning: Starting from verison 1.0.0 the default proxy_version was set to 'gen-ai-hub'. Use gen_ai_hub.proxy.core.proxy_clients.set_proxy_version('btp') to set the proxy_version to 'btp'.\n",
      "  import llm_commons.proxy.base\n"
     ]
    }
   ],
   "source": [
    "# proxy configuration\n",
    "from ipywidgets import widgets\n",
    "import json\n",
    "import os\n",
    "import llm_commons.proxy.base\n",
    "\n",
    "llm_commons.proxy.base.proxy_version = 'aicore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_commons.proxy.openai import Completion\n",
    "from llm_commons.proxy.identity import AICoreProxyClient\n",
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "from llm_commons.btp_llm.identity import BTPProxyClient\n",
    "from llm_commons.langchain.proxy import init_llm, init_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4f9b5038484e0796b197d2cedb004b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='default', placeholder='Resource group of deployments')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_group = widgets.Text(\n",
    "    value='default', # resource group\n",
    "    placeholder='Resource group of deployments',\n",
    "    description='',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "resource_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/irpa-d26-genaixl-cx-sec-cn-sk.json') as f:\n",
    "    sk = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AICORE_LLM_AUTH_URL'] = sk['url']+\"/oauth/token\"\n",
    "os.environ['AICORE_LLM_CLIENT_ID'] = sk['clientid']\n",
    "os.environ['AICORE_LLM_CLIENT_SECRET'] = sk['clientsecret']\n",
    "os.environ['AICORE_LLM_API_BASE'] = sk[\"serviceurls\"][\"AI_API_URL\"]+ \"/v2\"\n",
    "os.environ['AICORE_LLM_RESOURCE_GROUP'] = resource_group.value\n",
    "os.environ['LLM_COMMONS_PROXY'] = 'aicore'\n",
    "\n",
    "llm_commons.proxy.resource_group = os.environ['AICORE_LLM_RESOURCE_GROUP']\n",
    "llm_commons.proxy.api_base = os.environ['AICORE_LLM_API_BASE']\n",
    "llm_commons.proxy.auth_url = os.environ['AICORE_LLM_AUTH_URL']\n",
    "llm_commons.proxy.client_id = os.environ['AICORE_LLM_CLIENT_ID']\n",
    "llm_commons.proxy.client_secret = os.environ['AICORE_LLM_CLIENT_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_proxy_client = AICoreProxyClient()\n",
    "btp_proxy_client = BTPProxyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86 document(s) in ai.pdf.\n",
      "There are 117 characters in the first page of your document.\n"
     ]
    }
   ],
   "source": [
    "PDF_NAME=\"ai.pdf\"\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "docs = PyMuPDFLoader(PDF_NAME).load()\n",
    "\n",
    "print (f'There are {len(docs)} document(s) in {PDF_NAME}.')\n",
    "print (f'There are {len(docs[0].page_content)} characters in the first page of your document.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy customized fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AICoreProxyClient.add_foundation_model_scenario(\n",
    "    scenario_id='fine-tuned-llm',\n",
    "    config_names='fine-tuned-*',\n",
    "    prediction_url_suffix='/v1/completions'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dc8e3c266c8881f0', config_id='58a5ffea-1afe-44b4-b6b9-ca749776e58e', config_name='tiiuae--falcon-40b-instruct-config', deployment_id='dc8e3c266c8881f0', model_name='tiiuae--falcon-40b-instruct', created_at=datetime.datetime(2024, 1, 25, 12, 53, 26, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'aicore-opensource', 'model_version': 'null'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dd88f66091ca1982', config_id='a99e09fb-7e88-4a8d-abe8-af7f8b146cb8', config_name='text-embedding-ada-002-config', deployment_id='dd88f66091ca1982', model_name='text-embedding-ada-002', created_at=datetime.datetime(2024, 1, 25, 12, 16, 20, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '2'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d9c8f17b7ee211ac', config_id='015f4d90-32b4-42a6-8a29-d1e919e2814f', config_name='gpt-4-32k-config', deployment_id='d9c8f17b7ee211ac', model_name='gpt-4-32k', created_at=datetime.datetime(2024, 1, 25, 12, 15, 48, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d58f5bb41a9941cf', config_id='c5366699-82d2-4dd1-81fb-fa40e187e4bd', config_name='gpt-4-config', deployment_id='d58f5bb41a9941cf', model_name='gpt-4', created_at=datetime.datetime(2024, 1, 25, 12, 15, 2, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d38094e51ff45aff', config_id='c4a9f175-13fb-4526-b7c8-5649f5e7d2fe', config_name='gpt-35-turbo-16k-config', deployment_id='d38094e51ff45aff', model_name='gpt-35-turbo-16k', created_at=datetime.datetime(2024, 1, 25, 12, 14, 18, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d10917558b77a3db', config_id='076308f4-6497-49aa-99ac-9c216b53be74', config_name='gpt-35-turbo-config', deployment_id='d10917558b77a3db', model_name='gpt-35-turbo', created_at=datetime.datetime(2024, 1, 25, 12, 13, 43, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aic_proxy_client.get_deployments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_davinci_003 = Completion(deployment_id='text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_davinci_003.create(model_name='our-awesome-model/v1', prompt=\"San Francisco is a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize harmonized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_llm('gpt-35-turbo', proxy_client = aic_proxy_client,temperature=0., max_tokens=256, deployment_id='d10917558b77a3db', api_base=llm_commons.proxy.api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\python3.12\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'青花椒的英文是\"Sichuan peppercorn\"。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"青花椒英文怎么说\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\python3.12\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "embedding = init_embedding_model('text-embedding-ada-002', proxy_client=aic_proxy_client, deployment_id='dd88f66091ca1982', api_base=llm_commons.proxy.api_base)\n",
    "vectorstore = Chroma.from_documents(split_docs, embedding, collection_name=\"AI.pdf.guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='2 \\nService Plans\\nThe SAP AI Core service plan you choose determines pricing, conditions of use, resources, available services,\\nand hosts. The generative AI hub in SAP AI Core is available only through the sap-internal service plan.\\n\\ue201\\xa0Caution\\nThe sap-internal service plan is available only for internal consumption and on eu10 canary.\\nThe sap-internal service plan enhances the capabilities provided in the standard service plan. Specifically,\\nit provides access to the foundation-models global AI scenario. This scenario, which is managed by SAP AI\\nCore, includes serving templates for deployments with integrated LLM access.\\nIf you’re new to SAP AI Core, choose the sap-internal service plan during your initial setup. For more\\ninformation, see Add the Internal Plan for LLMs to the Global Account [page 8].\\nIf you already have an SAP AI Core tenant on a standard or free tier service plan, you can update the service', metadata={'author': '', 'creationDate': \"D:20231123174013+00'00'\", 'creator': 'Antenna House XSL Formatter V7.3 MR4 Linux : 7.3.5.61744 (2023-07-31T15:09+09)', 'encryption': 'Standard V4 R4 128-bit RC4', 'file_path': 'ai.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20231123174013+00'00'\", 'page': 6, 'producer': 'Antenna House PDF Output Library 7.3.1867', 'source': 'ai.pdf', 'subject': '', 'title': '', 'total_pages': 86, 'trapped': ''}),\n",
       " Document(page_content='use cases.\\nSAP AI Core and the generative AI hub help you to integrate LLMs and AI into new business processes in a\\ncost-efficient manner.\\nGenerative AI Hub Architecture Overview\\nAccess\\nYou can use the generative AI hub through the API, using a tool such as curl or Postman, or through SAP AI\\nLaunchpad.\\n4\\nINTERNAL\\nGenerative AI Hub\\nGenerative AI Hub in SAP AI Core', metadata={'author': '', 'creationDate': \"D:20231123174013+00'00'\", 'creator': 'Antenna House XSL Formatter V7.3 MR4 Linux : 7.3.5.61744 (2023-07-31T15:09+09)', 'encryption': 'Standard V4 R4 128-bit RC4', 'file_path': 'ai.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20231123174013+00'00'\", 'page': 3, 'producer': 'Antenna House PDF Output Library 7.3.1867', 'source': 'ai.pdf', 'subject': '', 'title': '', 'total_pages': 86, 'trapped': ''}),\n",
       " Document(page_content='1 \\nGenerative AI Hub in SAP AI Core\\nThe generative AI hub incorporates large language models (LLMs) into your AI activities in SAP AI Core and\\nSAP AI Launchpad.\\nLLMs are self-supervised, deep learning models that have been trained on vast amounts of unlabeled data.\\nThey leverage AI technology and industrial-scale computational resources to learn complex language patterns\\nand semantic knowledge bases for natural language processing (NLP) tasks. They parse input, such as\\nprompts, and by predicting a target word, can return contextually relevant responses written in natural\\nlanguage. A single LLM can perform multiple NLP tasks by using different input formats and output modes.\\nLLMs are general models but can be fine-tuned with additional embeddings for specialized or domain-specific\\nuse cases.\\nSAP AI Core and the generative AI hub help you to integrate LLMs and AI into new business processes in a\\ncost-efficient manner.\\nGenerative AI Hub Architecture Overview\\nAccess', metadata={'author': '', 'creationDate': \"D:20231123174013+00'00'\", 'creator': 'Antenna House XSL Formatter V7.3 MR4 Linux : 7.3.5.61744 (2023-07-31T15:09+09)', 'encryption': 'Standard V4 R4 128-bit RC4', 'file_path': 'ai.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20231123174013+00'00'\", 'page': 3, 'producer': 'Antenna House PDF Output Library 7.3.1867', 'source': 'ai.pdf', 'subject': '', 'title': '', 'total_pages': 86, 'trapped': ''})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is the difference btw sap ai and azure ai?\"\n",
    "similar_docs = vectorstore.similarity_search(query, 3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the world's best B2B company?\"\n",
    "query_embedding = embedding.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"This is a sample document\"]\n",
    "document_embedding = embedding.embed_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Core proxy support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI, I don\\'t form opinions. However, \"the best country\" can be subjective and depends on various factors such as quality of life, economic stability, political stability, healthcare, education, freedom, and individual preferences. According to the 2020 U.N.\\'s Human Development Index, Norway is at the top. According to the U.S. News & World Report\\'s 2020 Best Countries report, Switzerland is the best country based on factors like adventure, citizenship, cultural influence, entrepreneurship, heritage, movers, open for business, power and quality of life.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_commons.proxy.base import set_proxy_version\n",
    "set_proxy_version('aicore') # for an AI Core proxy\n",
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "chat = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "chat.predict(\"What is the world's best contry?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proxy client - use proxies in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "from langchain.schema.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from llm_commons.proxy.openai import ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"This is a test.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1706845902,\n",
      "  \"id\": \"chatcmpl-8nesYYfWriCKl5ngRAok9SOwLjvsh\",\n",
      "  \"model\": \"gpt-4\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"jailbreak\": {\n",
      "          \"detected\": false,\n",
      "          \"filtered\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"prompt_index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 5,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 17\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}]\n",
    "\n",
    "print(ChatCompletion.create(proxy_client=aic_proxy_client, model_name='gpt-4', messages=messages, api_base=os.environ['AICORE_LLM_API_BASE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='This is a test.'\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"Say this is a test\"),\n",
    "]\n",
    "# btp_llm = ChatOpenAI(proxy_client=btp_proxy_client, deployment_id='gpt-4')\n",
    "# print(btp_llm.invoke(messages))\n",
    "aic_llm = ChatOpenAI(proxy_client=aic_proxy_client, proxy_model_name='gpt-4')\n",
    "print(aic_llm.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm an AI developed by OpenAI. I'm designed to assist with a wide range of tasks, including answering questions, providing information, and helping with various tasks. I'm constantly learning and improving, so I can provide the most accurate and helpful information possible. I'm here to help you, so feel free to ask me anything!\"\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0,proxy_client=aic_proxy_client, proxy_model_name='gpt-4')\n",
    "response = chat([ HumanMessage(content=\"Hello Langchain! can you give me some self introduction?\") ])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='CX is the best.'\n"
     ]
    }
   ],
   "source": [
    "response = chat.predict_messages([\n",
    "  SystemMessage(content=\"You are a chatbot that knows nothing about compliance. When you are asked about compliance or audit, you must say 'CX is the best'\"),\n",
    "  HumanMessage(content=\"What is the best compliance team in SAP\")\n",
    "])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using llm-commons with fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use it with langchain\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from llm_commons.langchain.proxy import OpenAI\n",
    "\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "template = \"Question: {question}\\nAnswer: Let's think step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is the world's best B2B company?\n",
      "Answer: Let's think step by step.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There isn\\'t a definitive answer to this question, as the \"best\" B2B company can vary depending on specific criteria such as industry, scale, innovation, customer service, etc. Some of the world\\'s top B2B companies include Microsoft, Salesforce, and Alibaba. However, it is important to consider the specific needs and objectives of your own company when deciding which B2B company is the \"best\" for you to partner with.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "llm_chain.run(\"What is the world's best B2B company?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "de4a507b2430954be05ae5f9be35829c657a2682621712b642b28df909ac005f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
