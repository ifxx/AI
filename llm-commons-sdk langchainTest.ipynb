{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sap-llm-commons[all] in c:\\python\\3.11\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (8.1.7)\n",
      "Requirement already satisfied: text-generation>=0.6.0 in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (0.6.1)\n",
      "Requirement already satisfied: omegaconf in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (2.3.0)\n",
      "Requirement already satisfied: aleph-alpha-client in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (7.0.0)\n",
      "Requirement already satisfied: ai-core-sdk in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (1.22.3)\n",
      "Requirement already satisfied: langchain<=0.0.335,>=0.0.331 in c:\\python\\3.11\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.0.335)\n",
      "Requirement already satisfied: cohere>=4.27 in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (4.45)\n",
      "Requirement already satisfied: openai<1 in c:\\python\\3.11\\lib\\site-packages (from sap-llm-commons[all]) (0.28.1)\n",
      "Requirement already satisfied: colorama in c:\\python\\3.11\\lib\\site-packages (from click>=8.1.3->sap-llm-commons[all]) (0.4.6)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (3.9.1)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2.0,>=1.8 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (1.9.3)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (6.11.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\python\\3.11\\lib\\site-packages (from cohere>=4.27->sap-llm-commons[all]) (2.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2.0.25)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.0.84)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2.5.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python\\3.11\\lib\\site-packages (from langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (8.2.3)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.3.2 in c:\\python\\3.11\\lib\\site-packages (from langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.5.2)\n",
      "Requirement already satisfied: tqdm in c:\\python\\3.11\\lib\\site-packages (from openai<1->sap-llm-commons[all]) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.12 in c:\\python\\3.11\\lib\\site-packages (from text-generation>=0.6.0->sap-llm-commons[all]) (0.20.3)\n",
      "Requirement already satisfied: ai-api-client-sdk==1.28.0 in c:\\python\\3.11\\lib\\site-packages (from ai-core-sdk->sap-llm-commons[all]) (1.28.0)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk==1.28.0->ai-core-sdk->sap-llm-commons[all]) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk==1.28.0->ai-core-sdk->sap-llm-commons[all]) (3.8.0)\n",
      "Requirement already satisfied: aiodns>=3.0.0 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (3.1.1)\n",
      "Requirement already satisfied: aiohttp-retry>=2.8.3 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (2.8.3)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (4.6.2)\n",
      "Requirement already satisfied: Pillow>=9.2.0 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (9.5.0)\n",
      "Requirement already satisfied: python-liquid>=1.9.4 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (1.10.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\python\\3.11\\lib\\site-packages (from aleph-alpha-client->sap-llm-commons[all]) (23.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\python\\3.11\\lib\\site-packages (from omegaconf->sap-llm-commons[all]) (4.9.3)\n",
      "Requirement already satisfied: pycares>=4.0.0 in c:\\python\\3.11\\lib\\site-packages (from aiodns>=3.0.0->aleph-alpha-client->sap-llm-commons[all]) (4.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python\\3.11\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere>=4.27->sap-llm-commons[all]) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python\\3.11\\lib\\site-packages (from anyio<4.0->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python\\3.11\\lib\\site-packages (from anyio<4.0->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python\\3.11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python\\3.11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\python\\3.11\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text-generation>=0.6.0->sap-llm-commons[all]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python\\3.11\\lib\\site-packages (from huggingface-hub<1.0,>=0.12->text-generation>=0.6.0->sap-llm-commons[all]) (2023.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python\\3.11\\lib\\site-packages (from importlib_metadata<7.0,>=6.0->cohere>=4.27->sap-llm-commons[all]) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python\\3.11\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python\\3.11\\lib\\site-packages (from pydantic<3,>=1->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\python\\3.11\\lib\\site-packages (from pydantic<3,>=1->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2.14.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python\\3.11\\lib\\site-packages (from python-liquid>=1.9.4->aleph-alpha-client->sap-llm-commons[all]) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0.0,>=2.25.0->cohere>=4.27->sap-llm-commons[all]) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0.0,>=2.25.0->cohere>=4.27->sap-llm-commons[all]) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python\\3.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python\\3.11\\lib\\site-packages (from tiktoken<0.6.0,>=0.3.2->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (2023.12.25)\n",
      "Requirement already satisfied: cffi>=1.5.0 in c:\\python\\3.11\\lib\\site-packages (from pycares>=4.0.0->aiodns>=3.0.0->aleph-alpha-client->sap-llm-commons[all]) (1.15.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\3.11\\lib\\site-packages (from python-dateutil>=2.8.1->python-liquid>=1.9.4->aleph-alpha-client->sap-llm-commons[all]) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python\\3.11\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<=0.0.335,>=0.0.331->langchain[openai]<=0.0.335,>=0.0.331; extra == \"all\"->sap-llm-commons[all]) (1.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\python\\3.11\\lib\\site-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns>=3.0.0->aleph-alpha-client->sap-llm-commons[all]) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sap-llm-commons[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ai-api-client-sdk in c:\\python\\3.11\\lib\\site-packages (1.28.0)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk) (3.8.0)\n",
      "Requirement already satisfied: requests<3.0 in c:\\python\\3.11\\lib\\site-packages (from ai-api-client-sdk) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\3.11\\lib\\site-packages (from requests<3.0->ai-api-client-sdk) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ai-api-client-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylin\\AppData\\Local\\Temp\\ipykernel_10688\\3646097473.py:5: UserWarning: Starting from verison 1.0.0 the default proxy_version was set to 'gen-ai-hub'. Use gen_ai_hub.proxy.core.proxy_clients.set_proxy_version('btp') to set the proxy_version to 'btp'.\n",
      "  import llm_commons.proxy.base\n"
     ]
    }
   ],
   "source": [
    "# proxy configuration\n",
    "from ipywidgets import widgets\n",
    "import json\n",
    "import os\n",
    "import llm_commons.proxy.base\n",
    "\n",
    "llm_commons.proxy.base.proxy_version = 'aicore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_commons.proxy.openai import Completion\n",
    "from llm_commons.proxy.identity import AICoreProxyClient\n",
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "from llm_commons.btp_llm.identity import BTPProxyClient\n",
    "from llm_commons.langchain.proxy import init_llm, init_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b026cd22ff44378b24d091eda71f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='default', placeholder='Resource group of deployments')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_group = widgets.Text(\n",
    "    value='default', # resource group\n",
    "    placeholder='Resource group of deployments',\n",
    "    description='',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "resource_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/irpa-d26-genaixl-cx-sec-cn-sk.json') as f:\n",
    "    sk = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AICORE_LLM_AUTH_URL'] = sk['url']+\"/oauth/token\"\n",
    "os.environ['AICORE_LLM_CLIENT_ID'] = sk['clientid']\n",
    "os.environ['AICORE_LLM_CLIENT_SECRET'] = sk['clientsecret']\n",
    "os.environ['AICORE_LLM_API_BASE'] = sk[\"serviceurls\"][\"AI_API_URL\"]+ \"/v2\"\n",
    "os.environ['AICORE_LLM_RESOURCE_GROUP'] = resource_group.value\n",
    "os.environ['LLM_COMMONS_PROXY'] = 'aicore'\n",
    "os.environ[\"TAVILY_API_KEY\"] = sk['tavily']\n",
    "\n",
    "llm_commons.proxy.resource_group = os.environ['AICORE_LLM_RESOURCE_GROUP']\n",
    "llm_commons.proxy.api_base = os.environ['AICORE_LLM_API_BASE']\n",
    "llm_commons.proxy.auth_url = os.environ['AICORE_LLM_AUTH_URL']\n",
    "llm_commons.proxy.client_id = os.environ['AICORE_LLM_CLIENT_ID']\n",
    "llm_commons.proxy.client_secret = os.environ['AICORE_LLM_CLIENT_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_proxy_client = AICoreProxyClient()\n",
    "btp_proxy_client = BTPProxyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86 document(s) in ai.pdf.\n",
      "There are 117 characters in the first page of your document.\n"
     ]
    }
   ],
   "source": [
    "PDF_NAME=\"ai.pdf\"\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "docs = PyMuPDFLoader(PDF_NAME).load()\n",
    "\n",
    "print (f'There are {len(docs)} document(s) in {PDF_NAME}.')\n",
    "print (f'There are {len(docs[0].page_content)} characters in the first page of your document.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy customized fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AICoreProxyClient.add_foundation_model_scenario(\n",
    "    scenario_id='fine-tuned-llm',\n",
    "    config_names='fine-tuned-*',\n",
    "    prediction_url_suffix='/v1/completions'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dc8e3c266c8881f0', config_id='58a5ffea-1afe-44b4-b6b9-ca749776e58e', config_name='tiiuae--falcon-40b-instruct-config', deployment_id='dc8e3c266c8881f0', model_name='tiiuae--falcon-40b-instruct', created_at=datetime.datetime(2024, 1, 25, 12, 53, 26, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'aicore-opensource', 'model_version': 'null'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dd88f66091ca1982', config_id='a99e09fb-7e88-4a8d-abe8-af7f8b146cb8', config_name='text-embedding-ada-002-config', deployment_id='dd88f66091ca1982', model_name='text-embedding-ada-002', created_at=datetime.datetime(2024, 1, 25, 12, 16, 20, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '2'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d9c8f17b7ee211ac', config_id='015f4d90-32b4-42a6-8a29-d1e919e2814f', config_name='gpt-4-32k-config', deployment_id='d9c8f17b7ee211ac', model_name='gpt-4-32k', created_at=datetime.datetime(2024, 1, 25, 12, 15, 48, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d58f5bb41a9941cf', config_id='c5366699-82d2-4dd1-81fb-fa40e187e4bd', config_name='gpt-4-config', deployment_id='d58f5bb41a9941cf', model_name='gpt-4', created_at=datetime.datetime(2024, 1, 25, 12, 15, 2, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d38094e51ff45aff', config_id='c4a9f175-13fb-4526-b7c8-5649f5e7d2fe', config_name='gpt-35-turbo-16k-config', deployment_id='d38094e51ff45aff', model_name='gpt-35-turbo-16k', created_at=datetime.datetime(2024, 1, 25, 12, 14, 18, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d10917558b77a3db', config_id='076308f4-6497-49aa-99ac-9c216b53be74', config_name='gpt-35-turbo-config', deployment_id='d10917558b77a3db', model_name='gpt-35-turbo', created_at=datetime.datetime(2024, 1, 25, 12, 13, 43, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aic_proxy_client.get_deployments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_davinci_003 = Completion(deployment_id='text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_davinci_003.create(model_name='our-awesome-model/v1', prompt=\"San Francisco is a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize harmonized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_llm('gpt-35-turbo', proxy_client = aic_proxy_client,temperature=0., max_tokens=256, deployment_id='d10917558b77a3db', api_base=llm_commons.proxy.api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\python3.12\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'秋夜将晓出篱门，迎凉有感\\n\\n秋夜将晓，我走出篱门，\\n迎接着凉爽的秋风。\\n月亮渐渐西沉，星星点点闪烁，\\n夜空中弥漫着宁静的氛围。\\n\\n凉风拂过脸颊，带来一丝清凉，\\n让我感受到秋天的气息。\\n树叶沙沙作响，落下一地黄金，\\n仿佛是大自然送给我的礼物。\\n\\n我静静地站在篱门前，\\n凝望着远方的夜景。\\n思绪随着风儿飘荡，\\n回忆起往昔的点点滴滴。\\n\\n秋夜的寂静让我沉思，\\n回忆中的美好时光涌上心头。\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"请打印秋夜将晓出篱门迎凉有感这首诗\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\python3.12\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "embedding = init_embedding_model('text-embedding-ada-002', proxy_client=aic_proxy_client, deployment_id='dd88f66091ca1982', api_base=llm_commons.proxy.api_base)\n",
    "vectorstore = Chroma.from_documents(split_docs, embedding, collection_name=\"AI.pdf.guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='use cases.\\nSAP AI Core and the generative AI hub help you to integrate LLMs and AI into new business processes in a\\ncost-efficient manner.\\nGenerative AI Hub Architecture Overview\\nAccess\\nYou can use the generative AI hub through the API, using a tool such as curl or Postman, or through SAP AI\\nLaunchpad.\\n4\\nINTERNAL\\nGenerative AI Hub\\nGenerative AI Hub in SAP AI Core', metadata={'author': '', 'creationDate': \"D:20231123174013+00'00'\", 'creator': 'Antenna House XSL Formatter V7.3 MR4 Linux : 7.3.5.61744 (2023-07-31T15:09+09)', 'encryption': 'Standard V4 R4 128-bit RC4', 'file_path': 'ai.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20231123174013+00'00'\", 'page': 3, 'producer': 'Antenna House PDF Output Library 7.3.1867', 'source': 'ai.pdf', 'subject': '', 'title': '', 'total_pages': 86, 'trapped': ''}),\n",
       " Document(page_content='6.2 \\nConsume Large Language Models Using SAP AI Launchpad. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nQuestion Answering. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .64\\nSummarizing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\\nInferencing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\\n2\\nINTERNAL\\nGenerative AI Hub\\nContent', metadata={'author': '', 'creationDate': \"D:20231123174013+00'00'\", 'creator': 'Antenna House XSL Formatter V7.3 MR4 Linux : 7.3.5.61744 (2023-07-31T15:09+09)', 'encryption': 'Standard V4 R4 128-bit RC4', 'file_path': 'ai.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20231123174013+00'00'\", 'page': 1, 'producer': 'Antenna House PDF Output Library 7.3.1867', 'source': 'ai.pdf', 'subject': '', 'title': '', 'total_pages': 86, 'trapped': ''}),\n",
       " Document(page_content='6.1 \\nConsume Large Language Models Using SAP AI Core. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .43\\nSummarizing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nInferencing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nTransformations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\nExpansions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nChatbot. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\\n6.2 \\nConsume Large Language Models Using SAP AI Launchpad. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62', metadata={'author': '', 'creationDate': \"D:20231123174013+00'00'\", 'creator': 'Antenna House XSL Formatter V7.3 MR4 Linux : 7.3.5.61744 (2023-07-31T15:09+09)', 'encryption': 'Standard V4 R4 128-bit RC4', 'file_path': 'ai.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20231123174013+00'00'\", 'page': 1, 'producer': 'Antenna House PDF Output Library 7.3.1867', 'source': 'ai.pdf', 'subject': '', 'title': '', 'total_pages': 86, 'trapped': ''})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how can i use the sap ai instead of openai?\"\n",
    "similar_docs = vectorstore.similarity_search(query, 3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the world's best B2B company?\"\n",
    "query_embedding = embedding.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"This is a sample document\"]\n",
    "document_embedding = embedding.embed_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Core proxy support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This can vary depending on personal preferences, career goals and specific industries. However, as of 2020, according to \"Fortune\" magazine, the world\\'s best company to work for is Salesforce, a cloud-based software company based in San Francisco. They are praised for their strong company culture, benefits, and commitment to philanthropy. Other consistently high-ranking companies include Google, Microsoft, and The Walt Disney Company. The best company for an individual will depend on their own values, goals, and career interests.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_commons.proxy.base import set_proxy_version\n",
    "set_proxy_version('aicore') # for an AI Core proxy\n",
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "chat = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "chat.predict(\"What is the world's best company to work?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proxy client - use proxies in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "from langchain.schema.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from llm_commons.proxy.openai import ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"This is a test.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1708225873,\n",
      "  \"id\": \"chatcmpl-8tRs9nzsShKMzyDSBqnNL45BoDupX\",\n",
      "  \"model\": \"gpt-4\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"jailbreak\": {\n",
      "          \"detected\": false,\n",
      "          \"filtered\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"prompt_index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 5,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 17\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}]\n",
    "\n",
    "print(ChatCompletion.create(proxy_client=aic_proxy_client, model_name='gpt-4', messages=messages, api_base=os.environ['AICORE_LLM_API_BASE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='This is a test.'\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"Say this is a test\"),\n",
    "]\n",
    "# btp_llm = ChatOpenAI(proxy_client=btp_proxy_client, deployment_id='gpt-4')\n",
    "# print(btp_llm.invoke(messages))\n",
    "aic_llm = ChatOpenAI(proxy_client=aic_proxy_client, proxy_model_name='gpt-4')\n",
    "print(aic_llm.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\python3.12\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='12.57'\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0,proxy_client=aic_proxy_client, proxy_model_name='gpt-4')\n",
    "response = chat([ HumanMessage(content=\"半径为2的圆面积是多少，请直接给出答案以小数显示\") ])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\python3.12\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict_messages` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='CX is the best.'\n"
     ]
    }
   ],
   "source": [
    "response = chat.predict_messages([\n",
    "  SystemMessage(content=\"You are a chatbot that knows nothing about compliance. When you are asked about compliance or audit, you must say 'CX is the best'\"),\n",
    "  HumanMessage(content=\"What is the best compliance team in SAP\")\n",
    "])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test a search api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.google.com/finance/quote/SAP:NYSE',\n",
       "  'content': 'VIX 12.83 -1.76% -0.23 Home SAP • NYSE SAP SE Follow Share $181.18 After Hours: $181.18 (0.00%) 0.00 Closed: Feb 7, 4:09:01 PM GMT-5 · USD · NYSE · Disclaimer search Compare to Oracle Corp...'},\n",
       " {'url': 'https://finance.yahoo.com/quote/SAP/',\n",
       "  'content': 'Crypto Sectors Contact Us U.S. markets close in 44 minutes -3.60 +100.47(+0.26%) -37.28(-.23%) Russell 2000 +36.54(+1.82%) Crude Oil +0.05(+0.07%) Gold 2,033.50 -5.20(-0.26%) SAP SE (SAP) NYSE...'},\n",
       " {'url': 'https://www.bloomberg.com/quote/SAP:US',\n",
       "  'content': 'Stock analysis for SAP SE (SAP:New York) including stock price, stock chart, company news, key statistics, fundamentals and company profile.'},\n",
       " {'url': 'https://www.marketwatch.com/investing/stock/sap',\n",
       "  'content': 'Get the latest SAP stock price, news, analysis and charts for the German software giant. See how SAP performs in the cloud, AI and innovation markets, and how it compares to its peers and competitors.'},\n",
       " {'url': 'https://stockanalysis.com/stocks/sap/',\n",
       "  'content': 'Get the latest information on SAP SE, a global software company that provides enterprise application software products and services. See its stock performance, financials, analyst forecast, news, and more.'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tool = TavilySearchResults()\n",
    "tool.invoke({\"query\": \"sap stock\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using llm-commons with fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use it with langchain\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from llm_commons.langchain.proxy import OpenAI\n",
    "\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "template = \"Question: {question}\\nAnswer: Let's think step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\python3.12\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is the world's best B2B company?\n",
      "Answer: Let's think step by step.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It\\'s subjective to determine the \"best\" B2B company in the world, as it depends on various factors such as the industry, the company\\'s impact, its financial performance, customer satisfaction, and innovation. However, some top B2B companies include IBM, Alibaba, Microsoft, and Google Cloud. These companies have a significant impact in their respective industries and are renowned for their innovative solutions and services.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "llm_chain.run(\"What is the world's best B2B company?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['requests',\n",
       " 'requests_get',\n",
       " 'requests_post',\n",
       " 'requests_patch',\n",
       " 'requests_put',\n",
       " 'requests_delete',\n",
       " 'terminal',\n",
       " 'sleep',\n",
       " 'wolfram-alpha',\n",
       " 'google-search',\n",
       " 'google-search-results-json',\n",
       " 'searx-search-results-json',\n",
       " 'bing-search',\n",
       " 'metaphor-search',\n",
       " 'ddg-search',\n",
       " 'google-lens',\n",
       " 'google-serper',\n",
       " 'google-scholar',\n",
       " 'google-finance',\n",
       " 'google-trends',\n",
       " 'google-jobs',\n",
       " 'google-serper-results-json',\n",
       " 'searchapi',\n",
       " 'searchapi-results-json',\n",
       " 'serpapi',\n",
       " 'dalle-image-generator',\n",
       " 'twilio',\n",
       " 'searx-search',\n",
       " 'merriam-webster',\n",
       " 'wikipedia',\n",
       " 'arxiv',\n",
       " 'golden-query',\n",
       " 'pubmed',\n",
       " 'human',\n",
       " 'awslambda',\n",
       " 'stackexchange',\n",
       " 'sceneXplain',\n",
       " 'graphql',\n",
       " 'openweathermap-api',\n",
       " 'dataforseo-api-search',\n",
       " 'dataforseo-api-search-json',\n",
       " 'eleven_labs_text2speech',\n",
       " 'google_cloud_texttospeech',\n",
       " 'reddit_search',\n",
       " 'news-api',\n",
       " 'tmdb-api',\n",
       " 'podcast-api',\n",
       " 'memorize',\n",
       " 'llm-math',\n",
       " 'open-meteo-api']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import get_all_tool_names\n",
    "get_all_tool_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe error message indicates that you're trying to access a method or attribute named 'config_list_from_json' from a module named 'autogen', but the module does not have this method or attribute. This could be because the 'config_list_from_json' function doesn't exist in the 'autogen' module, it's not correctly imported, or the 'autogen' module itself might not be correctly installed or imported. Make sure that you have correctly spelled the method or attribute name, and that it exists in the 'autogen' module. Also, check your import statements to confirm that the module is correctly imported. If the function is part of a class in the module, you'll need to create an instance of the class to use the function.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The error message indicates that you're trying to access a method or attribute named 'config_list_from_json' from a module named 'autogen', but the module does not have this method or attribute. This could be because the 'config_list_from_json' function doesn't exist in the 'autogen' module, it's not correctly imported, or the 'autogen' module itself might not be correctly installed or imported. Make sure that you have correctly spelled the method or attribute name, and that it exists in the 'autogen' module. Also, check your import statements to confirm that the module is correctly imported. If the function is part of a class in the module, you'll need to create an instance of the class to use the function.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "# set up the agent\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search)\n",
    "\n",
    "# initialize the agent\n",
    "agent_chain = initialize_agent(\n",
    "    [tavily_tool],\n",
    "    llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# run the agent\n",
    "agent_chain.run(\n",
    "    \"AttributeError: module 'autogen' has no attribute 'config_list_from_json'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyautogen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyautogen\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m(autogen))\n\u001b[0;32m      4\u001b[0m config_list \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mconfig_list_from_json(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOAI_CONFIG_LIST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     filter_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-35-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m     },\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyautogen'"
     ]
    }
   ],
   "source": [
    "import pyautogen\n",
    "print(dir(autogen))\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt4\", \"gpt-35-turbo\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "de4a507b2430954be05ae5f9be35829c657a2682621712b642b28df909ac005f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
