{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"sap-llm-commons[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ai-api-client-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I541988\\AppData\\Local\\Temp\\ipykernel_1964\\3646097473.py:5: UserWarning: Starting from verison 1.0.0 the default proxy_version was set to 'gen-ai-hub'. Use gen_ai_hub.proxy.core.proxy_clients.set_proxy_version('btp') to set the proxy_version to 'btp'.\n",
      "  import llm_commons.proxy.base\n"
     ]
    }
   ],
   "source": [
    "# proxy configuration\n",
    "from ipywidgets import widgets\n",
    "import json\n",
    "import os\n",
    "import llm_commons.proxy.base\n",
    "\n",
    "llm_commons.proxy.base.proxy_version = 'aicore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_commons.proxy.openai import Completion\n",
    "from llm_commons.proxy.identity import AICoreProxyClient\n",
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "from llm_commons.btp_llm.identity import BTPProxyClient\n",
    "from llm_commons.langchain.proxy import init_llm, init_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd7841c949a4cfea1aa364e465de9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='default', placeholder='Resource group of deployments')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_group = widgets.Text(\n",
    "    value='default', # resource group\n",
    "    placeholder='Resource group of deployments',\n",
    "    description='',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "resource_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/irpa-d26-genaixl-cx-sec-cn-sk.json') as f:\n",
    "    sk = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AICORE_LLM_AUTH_URL'] = sk['url']+\"/oauth/token\"\n",
    "os.environ['AICORE_LLM_CLIENT_ID'] = sk['clientid']\n",
    "os.environ['AICORE_LLM_CLIENT_SECRET'] = sk['clientsecret']\n",
    "os.environ['AICORE_LLM_API_BASE'] = sk[\"serviceurls\"][\"AI_API_URL\"]+ \"/v2\"\n",
    "os.environ['AICORE_LLM_RESOURCE_GROUP'] = resource_group.value\n",
    "os.environ['LLM_COMMONS_PROXY'] = 'aicore'\n",
    "os.environ['TAVILY_API_KEY'] = sk['tavily']\n",
    "\n",
    "os.environ[\"BING_SUBSCRIPTION_KEY\"] = sk['bing']\n",
    "os.environ[\"BING_SEARCH_URL\"] = \"https://api.bing.microsoft.com/v7.0/search\"\n",
    "\n",
    "\n",
    "llm_commons.proxy.resource_group = os.environ['AICORE_LLM_RESOURCE_GROUP']\n",
    "llm_commons.proxy.api_base = os.environ['AICORE_LLM_API_BASE']\n",
    "llm_commons.proxy.auth_url = os.environ['AICORE_LLM_AUTH_URL']\n",
    "llm_commons.proxy.client_id = os.environ['AICORE_LLM_CLIENT_ID']\n",
    "llm_commons.proxy.client_secret = os.environ['AICORE_LLM_CLIENT_SECRET']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_proxy_client = AICoreProxyClient()\n",
    "btp_proxy_client = BTPProxyClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy customized fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AICoreProxyClient.add_foundation_model_scenario(\n",
    "    scenario_id='fine-tuned-llm',\n",
    "    config_names='fine-tuned-*',\n",
    "    prediction_url_suffix='/v1/completions'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dc8e3c266c8881f0', config_id='58a5ffea-1afe-44b4-b6b9-ca749776e58e', config_name='tiiuae--falcon-40b-instruct-config', deployment_id='dc8e3c266c8881f0', model_name='tiiuae--falcon-40b-instruct', created_at=datetime.datetime(2024, 1, 25, 12, 53, 26, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'aicore-opensource', 'model_version': 'null'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dd88f66091ca1982', config_id='a99e09fb-7e88-4a8d-abe8-af7f8b146cb8', config_name='text-embedding-ada-002-config', deployment_id='dd88f66091ca1982', model_name='text-embedding-ada-002', created_at=datetime.datetime(2024, 1, 25, 12, 16, 20, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '2'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d9c8f17b7ee211ac', config_id='015f4d90-32b4-42a6-8a29-d1e919e2814f', config_name='gpt-4-32k-config', deployment_id='d9c8f17b7ee211ac', model_name='gpt-4-32k', created_at=datetime.datetime(2024, 1, 25, 12, 15, 48, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d58f5bb41a9941cf', config_id='c5366699-82d2-4dd1-81fb-fa40e187e4bd', config_name='gpt-4-config', deployment_id='d58f5bb41a9941cf', model_name='gpt-4', created_at=datetime.datetime(2024, 1, 25, 12, 15, 2, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': '0613'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d38094e51ff45aff', config_id='c4a9f175-13fb-4526-b7c8-5649f5e7d2fe', config_name='gpt-35-turbo-16k-config', deployment_id='d38094e51ff45aff', model_name='gpt-35-turbo-16k', created_at=datetime.datetime(2024, 1, 25, 12, 14, 18, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None),\n",
       " Deployment(url='https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d10917558b77a3db', config_id='076308f4-6497-49aa-99ac-9c216b53be74', config_name='gpt-35-turbo-config', deployment_id='d10917558b77a3db', model_name='gpt-35-turbo', created_at=datetime.datetime(2024, 1, 25, 12, 13, 43, tzinfo=datetime.timezone.utc), additonal_parameters={'executable_id': 'azure-openai', 'model_version': 'latest'}, custom_prediction_suffix=None)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aic_proxy_client.get_deployments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_davinci_003 = Completion(deployment_id='text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_davinci_003.create(model_name='our-awesome-model/v1', prompt=\"San Francisco is a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize harmonized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_llm('gpt-35-turbo', proxy_client = aic_proxy_client,temperature=0., max_tokens=256, deployment_id='d10917558b77a3db', api_base=llm_commons.proxy.api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'白水绕东城。'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"青山横北郭，下一句是什么\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86 document(s) in ai.pdf.\n",
      "There are 117 characters in the first page of your document.\n"
     ]
    }
   ],
   "source": [
    "PDF_NAME=\"ai.pdf\"\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "docs = PyMuPDFLoader(PDF_NAME).load()\n",
    "\n",
    "print (f'There are {len(docs)} document(s) in {PDF_NAME}.')\n",
    "print (f'There are {len(docs[0].page_content)} characters in the first page of your document.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "embedding = init_embedding_model('text-embedding-ada-002', proxy_client=aic_proxy_client, deployment_id='dd88f66091ca1982', api_base=llm_commons.proxy.api_base)\n",
    "vectorstore = Chroma.from_documents(split_docs, embedding, collection_name=\"AI.pdf.guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='use cases.\\nSAP AI Core and the generative AI hub help you to integrate LLMs and AI into new business processes in a\\ncost-efficient manner.\\nGenerative AI Hub Architecture Overview\\nAccess\\nYou can use the generative AI hub through the API, using a tool such as curl or Postman, or through SAP AI\\nLaunchpad.\\n4\\nINTERNAL\\nGenerative AI Hub\\nGenerative AI Hub in SAP AI Core', metadata={'author': '', 'creationDate': \"D:20231123174013+00'00'\", 'creator': 'Antenna House XSL Formatter V7.3 MR4 Linux : 7.3.5.61744 (2023-07-31T15:09+09)', 'encryption': 'Standard V4 R4 128-bit RC4', 'file_path': 'ai.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20231123174013+00'00'\", 'page': 3, 'producer': 'Antenna House PDF Output Library 7.3.1867', 'source': 'ai.pdf', 'subject': '', 'title': '', 'total_pages': 86, 'trapped': ''}),\n",
       " Document(page_content='6.2 \\nConsume Large Language Models Using SAP AI Launchpad. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nQuestion Answering. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .64\\nSummarizing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\\nInferencing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\\n2\\nINTERNAL\\nGenerative AI Hub\\nContent', metadata={'author': '', 'creationDate': \"D:20231123174013+00'00'\", 'creator': 'Antenna House XSL Formatter V7.3 MR4 Linux : 7.3.5.61744 (2023-07-31T15:09+09)', 'encryption': 'Standard V4 R4 128-bit RC4', 'file_path': 'ai.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20231123174013+00'00'\", 'page': 1, 'producer': 'Antenna House PDF Output Library 7.3.1867', 'source': 'ai.pdf', 'subject': '', 'title': '', 'total_pages': 86, 'trapped': ''}),\n",
       " Document(page_content='6.1 \\nConsume Large Language Models Using SAP AI Core. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .43\\nSummarizing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nInferencing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nTransformations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\nExpansions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nChatbot. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\\n6.2 \\nConsume Large Language Models Using SAP AI Launchpad. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62', metadata={'author': '', 'creationDate': \"D:20231123174013+00'00'\", 'creator': 'Antenna House XSL Formatter V7.3 MR4 Linux : 7.3.5.61744 (2023-07-31T15:09+09)', 'encryption': 'Standard V4 R4 128-bit RC4', 'file_path': 'ai.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20231123174013+00'00'\", 'page': 1, 'producer': 'Antenna House PDF Output Library 7.3.1867', 'source': 'ai.pdf', 'subject': '', 'title': '', 'total_pages': 86, 'trapped': ''})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how can i use the sap ai instead of openai?\"\n",
    "similar_docs = vectorstore.similarity_search(query, 3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the world's best B2B company?\"\n",
    "query_embedding = embedding.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"This is a sample document\"]\n",
    "document_embedding = embedding.embed_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Core proxy support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This can vary depending on individual preferences, career field, and personal values. However, according to Fortune\\'s annual list, the best company to work for in 2020 was Hilton. Other consistently top-ranked companies include Google, Salesforce, and Microsoft. It\\'s also important to note that the \"best\" company can greatly vary depending on factors such as work-life balance, company culture, benefits, and career growth opportunities.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_commons.proxy.base import set_proxy_version\n",
    "set_proxy_version('aicore') # for an AI Core proxy\n",
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "chat = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "chat.predict(\"What is the world's best company to work?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proxy client - use proxies in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_commons.langchain.proxy import ChatOpenAI\n",
    "from langchain.schema.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from llm_commons.proxy.openai import ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}]\n",
    "\n",
    "# print(ChatCompletion.create(proxy_client=aic_proxy_client, model_name='gpt-4', messages=messages, api_base=os.environ['AICORE_LLM_API_BASE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='This is a test.'\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"Say this is a test\"),\n",
    "]\n",
    "# btp_llm = ChatOpenAI(proxy_client=btp_proxy_client, deployment_id='gpt-4')\n",
    "# print(btp_llm.invoke(messages))\n",
    "aic_llm = ChatOpenAI(proxy_client=aic_proxy_client, proxy_model_name='gpt-4')\n",
    "print(aic_llm.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\3.11\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='12.57'\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0,proxy_client=aic_proxy_client, proxy_model_name='gpt-4')\n",
    "response = chat([ HumanMessage(content=\"半径为2的圆面积是多少，请直接给出答案以小数显示\") ])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\3.11\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict_messages` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='CX is the best.'\n"
     ]
    }
   ],
   "source": [
    "response = chat.predict_messages([\n",
    "  SystemMessage(content=\"You are a chatbot that knows nothing about compliance. When you are asked about compliance or audit, you must say 'CX is the best'\"),\n",
    "  HumanMessage(content=\"What is the best compliance team in SAP\")\n",
    "])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test a search api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://time.com/6240741/messi-ronaldo-greatest-of-all-time-stats-comparison/',\n",
       "  'content': 'But as they each prepare to leave the stage in the coming years, there’s an ascendant generation—from 23-year-old French phenom Kylian Mbappé, the world’s highest-paid soccer player who already has a World Cup trophy under his belt and scored thrice in the final on Sunday to almost win his second, to 22-year-old Erling Haaland, Manchester City’s Norwegian rising star who in the last four years has scored 159 goals in 156 games for clubs and country—vying to take their places at the perch of the world’s most popular sport.\\n Senior International Tournaments Besides the World Cup\\nMessi: 2 (2021 Copa América, 2022 CONMEBOL-UEFA Cup of Champions) Ronaldo: 2 (2016 European Championship, 2019 UEFA Nations League)\\nFIFA World Cups\\nMessi: 1 (2022) Ronaldo: 0\\nIcons on the field and off it (they’re the two most-followed Instagram accounts in the world), Messi and Ronaldo are both arguably better than any men’s soccer player to have come before them.\\n UEFA Champions League Titles\\nMessi: 4 (2006, 2009, 2011, 2015 with Barcelona) Ronaldo: 5 (2008 with Manchester United; 2014, 2016, 2017, 2018 with Real Madrid)\\nUEFA Super Cups\\nMessi: 3 (2009, 2011, 2015 with Barcelona) Ronaldo: 4 (2008 with Manchester United; 2014, 2016, 2017 with Real Madrid)\\nFIFA Club World Cups\\nMessi: 3 (2009, 2011, 2015 with Barcelona) Ronaldo: 4 (2008 with Manchester United; 2014, 2016, 2017 with Real Madrid)\\n Domestic Cups\\nMessi: 16 (Supercopa de España in 2005, 2006, 2009, 2010, 2011, 2013, 2016, 2018; Copa del Rey in 2009, 2012, 2015, 2016, 2017, 2018, 2021; Trophée des Champions in 2022) Ronaldo: 13 (Supertaça Cândido de Oliveira in 2002; FA Cup in 2004; EFL Cup in 2006, 2009; FA Community Shield in 2007, 2008; Copa del Rey in 2011, 2014; Supercopa de España in 2012, 2017; Supercoppa Italiana in 2019, 2021; Coppa Italia in 2021)\\n Domestic League Player of the Season Awards\\nMessi: 9 (La Liga: 2008-2009, 2009-2010, 2010-2011, 2011-2012, 2012-2013, 2014-2015, 2016-2017, 2017-2018, 2018-2019) Ronaldo: 5 (Premier League: 2006-2007, 2007-2008; La Liga: 2013-2014; Serie A: 2018-2019, 2019-2020)\\nInternational Golden Boots\\nMessi: 1 (2021 Copa América) Ronaldo: 2 (2019 UEFA Nations League, 2020 European Championship)\\n'},\n",
       " {'url': 'https://www.guinnessworldrecords.com/news/2022/11/messi-vs-ronaldo-who-is-truly-the-goat-725980',\n",
       "  'content': \"Messi and Ronaldo have both played in five World Cups, sharing the record for the most appearances in FIFA World Cup tournaments by a player (male),\\xa0however, Messi failed to score in 2010’s tournament, handing Ronaldo the record for the most FIFA World Cup tournaments scored in by a player (5). Beyond the World Cup, Ronaldo has set several records in the UEFA European Championships:\\nOf course, as a South American, Messi cannot compete in the Euros, however, he equally holds the record of most appearances in the Copa America by a player (34, tied with Chile’s Sergio Livingstone).\\n At the 2022 Qatar World Cup, both players registered a 'first' in the record books: Ronaldo became the\\xa0first player to score in five different World Cups (male) and Messi became the first player to assist in five different World Cups (male).\\n Messi also pulled ahead of Ronaldo for the most Man of the Match awards won at the World Cup (11), after adding five to his collection at the tournament on his way to lifting the trophy.\\n Ronaldo has the most goals in the FIFA Club World Cup by an individual (7) and the most goals scored in a FIFA Club World Cup game by an individual (3, tied with Luis Suárez and Gareth Bale).\\n\"},\n",
       " {'url': 'https://www.nytimes.com/2023/10/30/sports/soccer/messi-wins-ballon-dor.html',\n",
       "  'content': 'She topped that with her performance in the World Cup, which technically took place outside the window for which players were judged, scoring three goals and winning the tournament’s M.V.P. award as Spain defeated England, 1-0, in the final in Sydney in August.\\n Messi’s eighth Ballon d’Or is another positive tally in his long-running battle for best player of his generation with the Portuguese forward Cristiano Ronaldo, who is second on the all-time list with five of the awards, which date to 1956. The pre-award debate centered on whether Messi’s amazing month at the World Cup should trump the fine yearlong play of the Norwegian striker Erling Haaland, who won just about every club trophy available with mighty Manchester City. By Victor Mather\\nThe Ballon d’Or, the most prestigious individual soccer award of the year, rewards the best player over a 12-month period. Messi, 36, was awarded the prize on Monday for the eighth time, and the first time since he signed with Inter Miami of Major League Soccer in July.'},\n",
       " {'url': 'https://www.sportingnews.com/us/soccer/news/lionel-messi-team-world-cup-2022-soccer/pyan3de8jqalupyqzzthkax8',\n",
       "  'content': \"Who does Lionel Messi play for in the World Cup?\\nMessi is Argentina's No. 10, following in the footsteps of iconic Argentinian playmaker Diego Maradona.\\n However, after a series of financial issues (which still persist), Barça were forced to let Messi — the highest-paid player in the world — leave following the 2020-21 season.\\n He nabbed another Balon D'Or in 2021 and is continuing to put on a clinic even at the age of 35 — he has seven goals and ten assists in 13 games for PSG this season.\\n In 2021, Messi led Argentina to a Copa America title, meaning that the Argentinians reign supreme as the best team in South America at the moment. And, for likely the final time, fans will be able to witness him perform on the grand stage: the World Cup.\\n\"},\n",
       " {'url': 'https://www.transfermarkt.com/lionel-messi/profil/spieler/28003',\n",
       "  'content': 'Lionel Messi - Player profile 2024 | Transfermarkt New arrival #10 Lionel Messi 8 8 1 1 4 Miami MLS League level: First Tier Joined: Jul 15, 2023 Contract expires: Dec 31, 2025 imago images + Date of birth/Age: Jun 24, 1987 (36) Place of birth: Rosario Citizenship: Argentina Height: 1,70 m Position: Right Winger Current international: Argentina'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tool = TavilySearchResults()\n",
    "tool.invoke({\"query\": \"sap stock\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using llm-commons with fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use it with langchain\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from llm_commons.langchain.proxy import OpenAI\n",
    "\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "template = \"Question: {question}\\nAnswer: Let's think step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is the world's best B2B company?\n",
      "Answer: Let's think step by step.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This is subjective as it depends on various factors such as one\\'s personal experience with the company, the industry one is in, and what one considers as \"best\". However, some of the globally renowned B2B companies include IBM, Alibaba, and Microsoft. These companies have a wide range of products and services and have been recognized for their innovation, customer service, and impact on their respective industries.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "llm_chain.run(\"What is the world's best B2B company?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['requests',\n",
       " 'requests_get',\n",
       " 'requests_post',\n",
       " 'requests_patch',\n",
       " 'requests_put',\n",
       " 'requests_delete',\n",
       " 'terminal',\n",
       " 'sleep',\n",
       " 'wolfram-alpha',\n",
       " 'google-search',\n",
       " 'google-search-results-json',\n",
       " 'searx-search-results-json',\n",
       " 'bing-search',\n",
       " 'metaphor-search',\n",
       " 'ddg-search',\n",
       " 'google-lens',\n",
       " 'google-serper',\n",
       " 'google-scholar',\n",
       " 'google-finance',\n",
       " 'google-trends',\n",
       " 'google-jobs',\n",
       " 'google-serper-results-json',\n",
       " 'searchapi',\n",
       " 'searchapi-results-json',\n",
       " 'serpapi',\n",
       " 'dalle-image-generator',\n",
       " 'twilio',\n",
       " 'searx-search',\n",
       " 'merriam-webster',\n",
       " 'wikipedia',\n",
       " 'arxiv',\n",
       " 'golden-query',\n",
       " 'pubmed',\n",
       " 'human',\n",
       " 'awslambda',\n",
       " 'stackexchange',\n",
       " 'sceneXplain',\n",
       " 'graphql',\n",
       " 'openweathermap-api',\n",
       " 'dataforseo-api-search',\n",
       " 'dataforseo-api-search-json',\n",
       " 'eleven_labs_text2speech',\n",
       " 'google_cloud_texttospeech',\n",
       " 'reddit_search',\n",
       " 'news-api',\n",
       " 'tmdb-api',\n",
       " 'podcast-api',\n",
       " 'memorize',\n",
       " 'llm-math',\n",
       " 'open-meteo-api']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import get_all_tool_names\n",
    "get_all_tool_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The assistant cannot predict future stock prices as it's against policy and it's impossible to predict the stock market. \n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"I'm sorry, but I can't provide the information you're looking for. It's impossible to predict future stock prices.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I can't provide the information you're looking for. It's impossible to predict future stock prices.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "# set up the agent\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4')\n",
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search)\n",
    "\n",
    "# initialize the agent\n",
    "agent_chain = initialize_agent(\n",
    "    [tavily_tool],\n",
    "    llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# run the agent\n",
    "agent_chain.run(\n",
    "    \"how much sap stock price increased in 2023\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "de4a507b2430954be05ae5f9be35829c657a2682621712b642b28df909ac005f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
