{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/LangChain-Tutorials/blob/main/AutoGPT_with_LangChain_Primitives.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XTutPTRCW3g",
        "outputId": "17864dad-45b7-43bb-e10e-b4e8e4bd6072"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai tiktoken google-search-results chromadb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ38dO_sFQsm"
      },
      "outputs": [],
      "source": [
        "# proxy configuration\n",
        "from ipywidgets import widgets\n",
        "import json\n",
        "import os\n",
        "import llm_commons.proxy.base\n",
        "\n",
        "llm_commons.proxy.base.proxy_version = 'aicore'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llm_commons.proxy.openai import Completion\n",
        "from llm_commons.proxy.identity import AICoreProxyClient\n",
        "from llm_commons.langchain.proxy import ChatOpenAI\n",
        "from llm_commons.btp_llm.identity import BTPProxyClient\n",
        "from llm_commons.langchain.proxy import init_llm, init_embedding_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('config/irpa-d26-genaixl-cx-sec-cn-sk.json') as f:\n",
        "    sk = json.load(f)\n",
        "\n",
        "os.environ['AICORE_LLM_RESOURCE_GROUP'] = 'default'\n",
        "os.environ[\"TAVILY_API_KEY\"] = sk['tavily']\n",
        "\n",
        "os.environ[\"BING_SUBSCRIPTION_KEY\"] = sk['bing']\n",
        "os.environ[\"BING_SEARCH_URL\"] = \"https://api.bing.microsoft.com/v7.0/search\"\n",
        "\n",
        "os.environ['AICORE_LLM_AUTH_URL'] = sk['url']+\"/oauth/token\"\n",
        "os.environ['AICORE_LLM_CLIENT_ID'] = sk['clientid']\n",
        "os.environ['AICORE_LLM_CLIENT_SECRET'] = sk['clientsecret']\n",
        "os.environ['AICORE_LLM_API_BASE'] = sk[\"serviceurls\"][\"AI_API_URL\"]+ \"/v2\"\n",
        "os.environ['LLM_COMMONS_PROXY'] = 'aicore'\n",
        "\n",
        "llm_commons.proxy.resource_group = os.environ['AICORE_LLM_RESOURCE_GROUP']\n",
        "llm_commons.proxy.api_base = os.environ['AICORE_LLM_API_BASE']\n",
        "llm_commons.proxy.auth_url = os.environ['AICORE_LLM_AUTH_URL']\n",
        "llm_commons.proxy.client_id = os.environ['AICORE_LLM_CLIENT_ID']\n",
        "llm_commons.proxy.client_secret = os.environ['AICORE_LLM_CLIENT_SECRET']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aic_proxy_client = AICoreProxyClient()\n",
        "btp_proxy_client = BTPProxyClient()\n",
        "embedding = init_embedding_model('text-embedding-ada-002', proxy_client=aic_proxy_client, deployment_id='dd88f66091ca1982', api_base=llm_commons.proxy.api_base)\n",
        "llm = ChatOpenAI(proxy_client=aic_proxy_client, proxy_model_name='gpt-4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEx9NAEqFCVn"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import BingSearchAPIWrapper\n",
        "from langchain.agents import Tool\n",
        "from langchain.tools.file_management.write import WriteFileTool\n",
        "from langchain.tools.file_management.read import ReadFileTool\n",
        "\n",
        "search = BingSearchAPIWrapper()\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events. You should ask targeted questions\"\n",
        "    ),\n",
        "    WriteFileTool(),\n",
        "    ReadFileTool(),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN-99CgRGF4y"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "vectordb = Chroma(persist_directory=\"./.chroma\", embedding_function=embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCqS4oHKGtWe"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.autonomous_agents import AutoGPT\n",
        "from llm_commons.langchain.proxy import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJTPwIHWGyIZ"
      },
      "outputs": [],
      "source": [
        "agent = AutoGPT.from_llm_and_tools(\n",
        "    ai_name=\"Xiaoming\",\n",
        "    ai_role=\"Assistant\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    memory=vectordb.as_retriever()\n",
        ")\n",
        "# Set verbose to be true\n",
        "agent.chain.verbose = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDD_7YXJG3dJ",
        "outputId": "f128318f-7be0-4362-da4a-3924bfae2b8e"
      },
      "outputs": [],
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "  agent.run([\"点（m,n）关于y=kx+b的对称点坐标是什么\"])\n",
        "  print(cb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US1MZMpBIUqA",
        "outputId": "dda5de4c-2275-463a-cdde-e8fbfe8a7b72"
      },
      "outputs": [],
      "source": [
        "!cat weather_report.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPbmzjXA4BB2FcG8A9hMjRN",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
